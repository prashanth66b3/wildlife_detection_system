{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMHiZjxO6PKa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdDDryR6Wo4R",
        "outputId": "625bace2-2afb-4528-ae9d-890596fcb2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Import libraries\n",
        "import os  # For interacting with the file system\n",
        "import shutil  # For managing files and directories in a cross-platform manner\n",
        "import keras  # For building deep learning models\n",
        "import numpy as np  # For numerical operations on arrays\n",
        "from glob import glob  # For finding file paths\n",
        "from tqdm import tqdm  # For progress bars\n",
        "\n",
        "# Data preprocessing\n",
        "from keras.preprocessing.image import ImageDataGenerator  # For image data augmentation\n",
        "\n",
        "# Data visualization\n",
        "import seaborn as sns  # For statistical visualizations\n",
        "import plotly.graph_objs as go  # For interactive visualizations\n",
        "import matplotlib.pyplot as plt  # For creating static plots\n",
        "\n",
        "# Model architecture\n",
        "from keras import Sequential  # For building sequential models\n",
        "from keras.models import load_model  # For loading pre-trained models\n",
        "from keras.layers import Dense, GlobalAvgPool2D as GAP, Dropout  # For defining model layers\n",
        "\n",
        "# Training callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping  # For training callbacks\n",
        "\n",
        "# Pre-trained models\n",
        "from tensorflow.keras.applications import InceptionV3, Xception, ResNet152V2  # For using pre-trained models"
      ],
      "metadata": {
        "id": "to5JcvmtWvkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the dataset\n",
        "data_path = '/content/drive/MyDrive/animals'\n",
        "\n",
        "# Get a list of class names from the data path\n",
        "class_names = sorted(os.listdir(data_path))\n",
        "\n",
        "# Count the number of classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Print the class names and the total number of classes\n",
        "print(\"Class Names: \\n\", class_names)\n",
        "print(\"Number of Classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6_9WLKmW2vO",
        "outputId": "4cf69e71-94fe-4997-9508-f03e9041bf4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Names: \n",
            " ['antelope', 'badger', 'bat', 'bear', 'bee', 'beetle', 'bison', 'boar', 'butterfly', 'cat', 'caterpillar', 'chimpanzee', 'cockroach', 'cow', 'coyote', 'crab', 'crow', 'deer', 'dog', 'dolphin', 'donkey', 'dragonfly', 'duck', 'eagle', 'elephant', 'flamingo', 'fly', 'fox', 'goat', 'goldfish', 'goose', 'gorilla', 'grasshopper', 'hamster', 'hare', 'hedgehog', 'hippopotamus', 'hornbill', 'horse', 'hummingbird', 'hyena', 'jellyfish', 'kangaroo', 'koala', 'ladybugs', 'leopard', 'lion', 'lizard', 'lobster', 'mosquito', 'moth', 'mouse', 'octopus', 'okapi', 'orangutan', 'otter', 'owl', 'ox', 'oyster', 'panda', 'parrot', 'pelecaniformes', 'penguin', 'pig', 'pigeon', 'porcupine', 'possum', 'raccoon', 'rat', 'reindeer', 'rhinoceros', 'sandpiper', 'seahorse', 'seal', 'shark', 'sheep', 'snake', 'sparrow', 'squid', 'squirrel', 'starfish', 'swan', 'tiger', 'turkey', 'turtle', 'whale', 'wolf', 'wombat', 'woodpecker', 'zebra']\n",
            "Number of Classes: 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of samples in each class\n",
        "class_sizes = []\n",
        "for name in class_names:\n",
        "    class_size = len(os.listdir(data_path + \"/\" + name))\n",
        "    class_sizes.append(class_size)\n",
        "\n",
        "# Print the class distribution\n",
        "print(\"Class Distribution:\\n\", class_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1YUEd-OXCl3",
        "outputId": "63ec3960-832c-42c5-8782-a34b8e58f281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            " [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 70, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to convert lists to dictionary **************\n",
        "class_name_size = dict(zip(class_names, class_sizes))"
      ],
      "metadata": {
        "id": "WNOyRPHIXFfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YUjxHJmXJxh",
        "outputId": "d44be611-71a9-416e-b937-9a54c83a2893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'antelope': 60,\n",
              " 'badger': 60,\n",
              " 'bat': 60,\n",
              " 'bear': 60,\n",
              " 'bee': 60,\n",
              " 'beetle': 60,\n",
              " 'bison': 60,\n",
              " 'boar': 60,\n",
              " 'butterfly': 60,\n",
              " 'cat': 60,\n",
              " 'caterpillar': 60,\n",
              " 'chimpanzee': 60,\n",
              " 'cockroach': 60,\n",
              " 'cow': 60,\n",
              " 'coyote': 60,\n",
              " 'crab': 60,\n",
              " 'crow': 60,\n",
              " 'deer': 60,\n",
              " 'dog': 60,\n",
              " 'dolphin': 60,\n",
              " 'donkey': 60,\n",
              " 'dragonfly': 60,\n",
              " 'duck': 60,\n",
              " 'eagle': 60,\n",
              " 'elephant': 60,\n",
              " 'flamingo': 60,\n",
              " 'fly': 60,\n",
              " 'fox': 60,\n",
              " 'goat': 60,\n",
              " 'goldfish': 60,\n",
              " 'goose': 60,\n",
              " 'gorilla': 60,\n",
              " 'grasshopper': 60,\n",
              " 'hamster': 60,\n",
              " 'hare': 60,\n",
              " 'hedgehog': 60,\n",
              " 'hippopotamus': 60,\n",
              " 'hornbill': 60,\n",
              " 'horse': 60,\n",
              " 'hummingbird': 60,\n",
              " 'hyena': 60,\n",
              " 'jellyfish': 60,\n",
              " 'kangaroo': 60,\n",
              " 'koala': 60,\n",
              " 'ladybugs': 60,\n",
              " 'leopard': 60,\n",
              " 'lion': 60,\n",
              " 'lizard': 60,\n",
              " 'lobster': 60,\n",
              " 'mosquito': 60,\n",
              " 'moth': 60,\n",
              " 'mouse': 60,\n",
              " 'octopus': 60,\n",
              " 'okapi': 60,\n",
              " 'orangutan': 60,\n",
              " 'otter': 60,\n",
              " 'owl': 60,\n",
              " 'ox': 60,\n",
              " 'oyster': 60,\n",
              " 'panda': 60,\n",
              " 'parrot': 60,\n",
              " 'pelecaniformes': 60,\n",
              " 'penguin': 60,\n",
              " 'pig': 60,\n",
              " 'pigeon': 60,\n",
              " 'porcupine': 60,\n",
              " 'possum': 60,\n",
              " 'raccoon': 60,\n",
              " 'rat': 60,\n",
              " 'reindeer': 60,\n",
              " 'rhinoceros': 60,\n",
              " 'sandpiper': 70,\n",
              " 'seahorse': 60,\n",
              " 'seal': 60,\n",
              " 'shark': 60,\n",
              " 'sheep': 60,\n",
              " 'snake': 60,\n",
              " 'sparrow': 60,\n",
              " 'squid': 60,\n",
              " 'squirrel': 60,\n",
              " 'starfish': 60,\n",
              " 'swan': 60,\n",
              " 'tiger': 60,\n",
              " 'turkey': 60,\n",
              " 'turtle': 60,\n",
              " 'whale': 60,\n",
              " 'wolf': 60,\n",
              " 'wombat': 60,\n",
              " 'woodpecker': 60,\n",
              " 'zebra': 60}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Generator with the specified image transformations and preprocessing\n",
        "# rescale: normalizes pixel values from 0-255 to 0-1\n",
        "# horizontal_flip: randomly flips images horizontally\n",
        "# vertical_flip: randomly flips images vertically\n",
        "# rotation_range: randomly rotates images by a given range in degrees\n",
        "# validation_split: splits the data into training and validation sets, with 20% of the data used for validation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    rotation_range=20,\n",
        "    validation_split=0.2)\n",
        "\n",
        "# Load training data from the specified directory and apply the generator\n",
        "# target_size: resizes the images to a specified size\n",
        "# class_mode: specifies the type of label encoding, binary for 2 classes\n",
        "# batch_size: specifies the number of samples per batch\n",
        "# shuffle: shuffles the data after each epoch\n",
        "# subset: specifies the subset of data to load, in this case, the training set\n",
        "train_data = data_generator.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=(256,256),\n",
        "    class_mode='binary',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    subset='training')\n",
        "\n",
        "# Load validation data from the specified directory and apply the generator\n",
        "# subset: specifies the subset of data to load, in this case, the validation set\n",
        "valid_data = data_generator.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=(256,256),\n",
        "    class_mode='binary',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muADYTLjXMWB",
        "outputId": "19e24517-2629-4f6f-a8a0-ef981b2ddc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4328 images belonging to 90 classes.\n",
            "Found 1082 images belonging to 90 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image, image_title=None):\n",
        "    '''\n",
        "    This function takes in an image and an optional title and plots the image.\n",
        "    '''\n",
        "    # Display the image\n",
        "    plt.imshow(image)\n",
        "\n",
        "    # Set the title of the plot if provided\n",
        "    plt.title(image_title)\n",
        "\n",
        "    # Turn off the axes in the plot\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "tKlqFrYvXRTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_data(data_tuple):\n",
        "    \"\"\"\n",
        "    Function to get a random data point from a given dataset.\n",
        "\n",
        "    Args:\n",
        "    data_tuple (tuple): A tuple containing the dataset images and labels as numpy arrays.\n",
        "\n",
        "    Returns:\n",
        "    A random image and its corresponding label as numpy arrays.\n",
        "    \"\"\"\n",
        "    images, labels = data_tuple\n",
        "    # get a random index for an image in the dataset\n",
        "    idx = np.random.randint(len(images))\n",
        "\n",
        "    # select the image and its corresponding label using the random index\n",
        "    image, label = images[idx], labels[idx]\n",
        "\n",
        "    # return the selected image and label\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "EXHWrdXSXTuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    #return image, label\n",
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "# Initialize a counter for the subplots\n",
        "counter=1\n",
        "\n",
        "# Loop over the train dataset\n",
        "for images, labels in iter(train_data):\n",
        "\n",
        "      # Get a random image and label\n",
        "      image, label = get_random_data([images, labels])\n",
        "\n",
        "      # Plot the image with its class name as the title\n",
        "      plt.subplot(5,5,counter)\n",
        "      show_image(image, image_title=f\"Class : {class_names[int(label)]}\")\n",
        "\n",
        "      # Increment the counter\n",
        "      counter+=1\n",
        "\n",
        "      # End the loop when 25 images have been plotted\n",
        "      if counter>=26: break\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K4DpzG27XVVF",
        "outputId": "751b6e0f-7013-47ff-c801-13ffbcc2fba3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"ResNet152V2\"\n",
        "\n",
        "# Load the pre-trained ResNet152V2 model, freeze its weights and exclude its final classification layer.\n",
        "base_model = ResNet152V2(include_top=False, input_shape=(256,256,3), weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a sequential model with the ResNet152V2 base model, a global average pooling layer, two fully connected layers, and a final softmax classification layer.\n",
        "resnet152V2 = Sequential([\n",
        "    base_model,\n",
        "    GAP(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "], name=name)\n",
        "\n",
        "# Compile the model with sparse categorical cross-entropy as the loss function, Adam optimizer and accuracy as the evaluation metric.\n",
        "resnet152V2.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Set up the EarlyStopping and ModelCheckpoint callbacks to monitor the training process and save the best model weights.\n",
        "cbs = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(name + \".h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train the model using the training and validation datasets, using 50 epochs and the previously defined callbacks.\n",
        "resnet152V2.fit(\n",
        "    train_data, validation_data=valid_data,\n",
        "    epochs=20, callbacks=cbs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cILC3XNBXZk6",
        "outputId": "fd623019-80e6-4666-f894-44017b38d645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "136/136 [==============================] - 144s 988ms/step - loss: 2.2967 - accuracy: 0.4778 - val_loss: 1.2077 - val_accuracy: 0.6867\n",
            "Epoch 2/20\n",
            "136/136 [==============================] - 131s 965ms/step - loss: 0.9903 - accuracy: 0.7364 - val_loss: 1.0148 - val_accuracy: 0.7292\n",
            "Epoch 3/20\n",
            "136/136 [==============================] - 132s 970ms/step - loss: 0.7383 - accuracy: 0.7918 - val_loss: 0.9876 - val_accuracy: 0.7357\n",
            "Epoch 4/20\n",
            "136/136 [==============================] - 132s 969ms/step - loss: 0.6295 - accuracy: 0.8149 - val_loss: 0.9147 - val_accuracy: 0.7514\n",
            "Epoch 5/20\n",
            "136/136 [==============================] - 132s 968ms/step - loss: 0.5293 - accuracy: 0.8445 - val_loss: 0.8381 - val_accuracy: 0.7736\n",
            "Epoch 6/20\n",
            "136/136 [==============================] - 132s 965ms/step - loss: 0.4608 - accuracy: 0.8602 - val_loss: 0.8204 - val_accuracy: 0.7800\n",
            "Epoch 7/20\n",
            "136/136 [==============================] - 131s 962ms/step - loss: 0.4057 - accuracy: 0.8794 - val_loss: 0.8538 - val_accuracy: 0.7828\n",
            "Epoch 8/20\n",
            "136/136 [==============================] - 132s 968ms/step - loss: 0.3597 - accuracy: 0.8916 - val_loss: 0.7961 - val_accuracy: 0.7939\n",
            "Epoch 9/20\n",
            "136/136 [==============================] - 132s 969ms/step - loss: 0.3016 - accuracy: 0.9085 - val_loss: 0.8209 - val_accuracy: 0.8059\n",
            "Epoch 10/20\n",
            "136/136 [==============================] - 131s 960ms/step - loss: 0.2818 - accuracy: 0.9131 - val_loss: 0.8245 - val_accuracy: 0.7902\n",
            "Epoch 11/20\n",
            "136/136 [==============================] - 133s 979ms/step - loss: 0.2848 - accuracy: 0.9134 - val_loss: 0.7811 - val_accuracy: 0.8050\n",
            "Epoch 12/20\n",
            "136/136 [==============================] - 145s 1s/step - loss: 0.2484 - accuracy: 0.9182 - val_loss: 0.7870 - val_accuracy: 0.7948\n",
            "Epoch 13/20\n",
            "136/136 [==============================] - 133s 980ms/step - loss: 0.2285 - accuracy: 0.9328 - val_loss: 0.7644 - val_accuracy: 0.8068\n",
            "Epoch 14/20\n",
            "136/136 [==============================] - 131s 965ms/step - loss: 0.2358 - accuracy: 0.9295 - val_loss: 0.8529 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "136/136 [==============================] - 130s 954ms/step - loss: 0.2152 - accuracy: 0.9323 - val_loss: 0.8167 - val_accuracy: 0.8078\n",
            "Epoch 16/20\n",
            "136/136 [==============================] - 131s 963ms/step - loss: 0.1986 - accuracy: 0.9369 - val_loss: 0.9188 - val_accuracy: 0.7819\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ff2bb1e7f10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-MN8z1u7XuSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/ResNetakhil.h5')"
      ],
      "metadata": {
        "id": "PyZ36vn-AzJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['antelope', 'badger', 'bat', 'bear', 'bee', 'beetle', 'bison', 'boar', 'butterfly', 'cat', 'caterpillar', 'chimpanzee', 'cockroach', 'cow', 'coyote', 'crab', 'crow', 'deer', 'dog', 'dolphin', 'donkey', 'dragonfly', 'duck', 'eagle', 'elephant', 'flamingo', 'fly', 'fox', 'goat', 'goldfish', 'goose', 'gorilla', 'grasshopper', 'hamster', 'hare', 'hedgehog', 'hippopotamus', 'hornbill', 'horse', 'hummingbird', 'hyena', 'jellyfish', 'kangaroo', 'koala', 'ladybugs', 'leopard', 'lion', 'lizard', 'lobster', 'mosquito', 'moth', 'mouse', 'octopus', 'okapi', 'orangutan', 'otter', 'owl', 'ox', 'oyster', 'panda', 'parrot', 'pelecaniformes', 'penguin', 'pig', 'pigeon', 'porcupine', 'possum', 'raccoon', 'rat', 'reindeer', 'rhinoceros', 'sandpiper', 'seahorse', 'seal', 'shark', 'sheep', 'snake', 'sparrow', 'squid', 'squirrel', 'starfish', 'swan', 'tiger', 'turkey', 'turtle', 'whale', 'wolf', 'wombat', 'woodpecker', 'zebra']\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    # Load the image using OpenCV or Pillow\n",
        "    img = cv2.imread(image_path)  # Example using OpenCV\n",
        "\n",
        "    # Resize the image\n",
        "    img = cv2.resize(img, (256, 256))  # Resize to 256x256 as in the training code\n",
        "\n",
        "    # Convert the image to a NumPy array\n",
        "    img = np.array(img)\n",
        "\n",
        "    # Rescale the pixel values from 0-255 to 0-1\n",
        "    img = img / 255.0\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess the test image\n",
        "test_image = preprocess_image('/content/tigdeerjpg.jpg')\n",
        "\n",
        "# Prepare the image for prediction\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "# Load the model (choose ResNet152V2 or Xception)\n",
        "  # Replace 'my_image_classifier.h5' with your desired filename\n",
        "\n",
        "\n",
        "# # Make predictions\n",
        "# predictions = model.predict(test_image)\n",
        "\n",
        "# # Get the predicted class index with the highest probability\n",
        "# predicted_class_index = np.argmax(predictions[0])\n",
        "\n",
        "# # Print the predicted class name\n",
        "# print(f\"Predicted Class: {class_names[predicted_class_index]}\")\n",
        "\n",
        "\n",
        "# # ... (Previous code, including preprocessing and loading the model)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_image)\n",
        "#print(predictions)\n",
        "# Get the predicted class index with the highest probability\n",
        "# Maximum probability among the predicted probabilities\n",
        "max_probability = np.max(predictions)\n",
        "\n",
        "# Threshold value (adjust as needed)\n",
        "threshold = 0.5\n",
        "\n",
        "# Check if the maximum probability is above the threshold\n",
        "if max_probability >= threshold:\n",
        "    # Get the predicted class index with the highest probability\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    # Print the predicted class name\n",
        "    print(f\"Predicted Class: {class_names[predicted_class_index]}\")\n",
        "else:\n",
        "    # Probability below threshold, classify as \"unknown\"\n",
        "    print(\"Unknown Sample\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ1RBd2fxlol",
        "outputId": "9290b8d2-60e0-4ff5-ea36-1ecbe25a2820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted Class: tiger (1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/ResNetakhil.h5')"
      ],
      "metadata": {
        "id": "C_qBdMvB1ePm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}